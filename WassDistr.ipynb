{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074753fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files. Loading data...\n",
      "Successfully loaded 1000 DataFrames.\n",
      "Aggregating global distribution...\n",
      "Calculating AVMs...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/zf0g09hn7t7696hbkn6tcyk80000gn/T/ipykernel_5190/2537156451.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Define your path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0msearch_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"paths1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Run the function (targeting index 0 for 'th1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavm_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_calculate_avm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# --- Plotting the Histogram ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/84/zf0g09hn7t7696hbkn6tcyk80000gn/T/ipykernel_5190/2537156451.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(search_dir, column_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mlocal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# scipy.stats.wasserstein_distance calculates the integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# of the absolute difference between the CDFs of two distributions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwasserstein_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mavm_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavm_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(u_values, v_values, u_weights, v_weights)\u001b[0m\n\u001b[1;32m  10427\u001b[0m     \u001b[0;34m...\u001b[0m                      \u001b[0;34m[\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10428\u001b[0m     \u001b[0;36m4.0781331438047861\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10430\u001b[0m     \"\"\"\n\u001b[0;32m> 10431\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_cdf_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(p, u_values, v_values, u_weights, v_weights)\u001b[0m\n\u001b[1;32m  10567\u001b[0m     \u001b[0mu_sorter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10568\u001b[0m     \u001b[0mv_sorter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10570\u001b[0m     \u001b[0mall_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10571\u001b[0;31m     \u001b[0mall_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10573\u001b[0m     \u001b[0;31m# Compute the differences between pairs of successive values of u and v.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10574\u001b[0m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def load_and_calculate_avm(search_dir, column_index=0):\n",
    "    \"\"\"\n",
    "    Loads CSV files, aggregates global data for a specific column,\n",
    "    and calculates the AVM (Area between CDFs) for each file against the global CDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Find files\n",
    "    search_pattern = os.path.join(search_dir, \"*.csv\")\n",
    "    csv_files = glob.glob(search_pattern)\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"Error: No .csv files found in directory '{search_dir}'\")\n",
    "        return [], []\n",
    "\n",
    "    print(f\"Found {len(csv_files)} files. Loading data...\")\n",
    "\n",
    "    # 2. Load data into a list (array) of DataFrames\n",
    "    data_frames = []\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        try:\n",
    "            # Read CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Ensure enough columns exist (User requirement: < 4 continue)\n",
    "            if len(df.columns) < 4:\n",
    "                continue\n",
    "                \n",
    "            data_frames.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {file_path}: {e}\")\n",
    "\n",
    "    if not data_frames:\n",
    "        print(\"No valid dataframes loaded.\")\n",
    "        return [], []\n",
    "\n",
    "    print(f\"Successfully loaded {len(data_frames)} DataFrames.\")\n",
    "\n",
    "    # 3. Aggregate Global Data (The \"Total Distribution\")\n",
    "    # We collect all values from the specific column (e.g., th1 at index 0)\n",
    "    # Using a list comprehension is memory efficient here before concatenation\n",
    "    print(\"Aggregating global distribution...\")\n",
    "    global_data = np.concatenate([df.iloc[:, column_index].values for df in data_frames])\n",
    "\n",
    "    # 4. Calculate AVM for each file\n",
    "    # AVM := Area between Global CDF and File CDF\n",
    "    print(\"Calculating AVMs...\")\n",
    "    avm_scores = []\n",
    "    \n",
    "    for df in data_frames:\n",
    "        local_data = df.iloc[:, column_index].values\n",
    "        \n",
    "        # scipy.stats.wasserstein_distance calculates the integral \n",
    "        # of the absolute difference between the CDFs of two distributions.\n",
    "        score = wasserstein_distance(global_data, local_data)\n",
    "        avm_scores.append(score)\n",
    "\n",
    "    return data_frames, avm_scores\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "# Define your path\n",
    "search_dir = \"paths1\" \n",
    "\n",
    "# Run the function (targeting index 0 for 'th1')\n",
    "dfs, avm_results = load_and_calculate_avm(search_dir, column_index=0)\n",
    "\n",
    "# --- Plotting the Histogram ---\n",
    "\n",
    "if avm_results:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot histogram\n",
    "    plt.hist(avm_results, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title(r'Histogram of Area Validation Metrics (AVM) for $th_1$', fontsize=14)\n",
    "    plt.xlabel(r'AVM: $\\int | F_{total}(s) - F_{file}(s) | ds$', fontsize=12)\n",
    "    plt.ylabel('Frequency (Number of Files)', fontsize=12)\n",
    "    \n",
    "    # Add a mean line for reference\n",
    "    mean_avm = np.mean(avm_results)\n",
    "    plt.axvline(mean_avm, color='red', linestyle='dashed', linewidth=1, label=f'Mean AVM: {mean_avm:.4f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
